{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import utils_graphsage_1 as utils\n",
    "import torch\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toeplitz(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed=114514\n",
    "seed = 41222\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.seed_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"../data/opsahl-ucsocial/data.csv\")\n",
    "data = data.drop_duplicates(subset=['start','end'])\n",
    "node_to_id = dict()\n",
    "node_type_dict = dict()\n",
    "for node in list(data['start']) + list(data['end']):\n",
    "    node = int(node)\n",
    "    if node not in node_to_id:\n",
    "        node_to_id[node] = len(node_to_id)\n",
    "for node in list(data['start']):\n",
    "    node = node_to_id[int(node)]\n",
    "    node_type_dict[node] = 1 ### user type node\n",
    "for node in list(data['end']):\n",
    "    node = node_to_id[int(node)]\n",
    "    node_type_dict[node] = 0 ### item type node\n",
    "\n",
    "#edges = defaultdict(lambda: 0)\n",
    "train_ones = []\n",
    "feature_dict = {}\n",
    "for start,end in data[['start','end']].values:\n",
    "    start,end = int(start),int(end)\n",
    "    start = node_to_id[start]\n",
    "    end = node_to_id[end]\n",
    "    train_ones.append([int(start),int(end)])\n",
    "train_ones= np.array(train_ones)\n",
    "print(len(train_ones))\n",
    "print(train_ones[:5])\n",
    "### There can be multiple edges between same node  pairs\n",
    "\n",
    "\n",
    "adj_sparse = np.zeros((np.max(train_ones)+1,np.max(train_ones)+1))\n",
    "for e in train_ones:\n",
    "    adj_sparse[e[0],e[1]]=1\n",
    "    adj_sparse[e[1],e[0]]=1\n",
    "    \n",
    "adj_sparse = sp.coo_matrix(adj_sparse).tocsr()\n",
    "\n",
    "# lcc = utils.largest_connected_components(adj_sparse)\n",
    "# adj_sparse= adj_sparse[lcc,:][:,lcc]\n",
    "_N = adj_sparse.shape[0]\n",
    "print('n',_N)\n",
    "_Edges=[]\n",
    "for x in np.column_stack(adj_sparse.nonzero()):\n",
    "    if not x[0]==x[1]:\n",
    "        _Edges.append((x[0],x[1]))\n",
    "_num_of_edges=int(len(_Edges)/2)\n",
    "print('m',_num_of_edges)\n",
    "\n",
    "dic=defaultdict(set)\n",
    "for x in _Edges:\n",
    "    a1=x[0]\n",
    "    a2=x[1]\n",
    "    dic[a1].add(a2)\n",
    "    dic[a2].add(a1)\n",
    "    \n",
    "\n",
    "adj_origin=np.zeros((_N,_N)).astype(int)  ### extra dimension for node type\n",
    "for (i,j) in _Edges:\n",
    "    adj_origin[i][j]=1\n",
    "    adj_origin[j][i]=1\n",
    "assert(np.sum(adj_origin==adj_origin.T)==_N*_N)\n",
    "assert(np.sum(adj_origin)==_num_of_edges*2)\n",
    "\n",
    "\n",
    "embedding_dim=128\n",
    "\n",
    "graphsagemodel=utils.GraphSAGE(_N=_N,_M=_num_of_edges,adj_origin=adj_origin,feat_matrix = adj_origin,\n",
    "                                         adj_dic=dic,embedding_dim=embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.Get link prediction model and embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *1.1 Load pretrained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsagemodel.load_model(path='models/gf_msg/graphsage0_87.pth',embedding_path='models/gf_msg/embedding_matrix0_87.pth.npy')\n",
    "embedding_matrix_numpy=graphsagemodel.embedding_matrix_numpy\n",
    "link_prediction_model=graphsagemodel.graphsage_link_prediction_from_embedding_one_to_other\n",
    "predict_adj=utils.evaluate_overlap_torch(_N=_N,\n",
    "                                                    _num_of_edges=_num_of_edges,\n",
    "                                                    adj_origin=adj_origin,\n",
    "                                                    embedding_matrix_numpy=embedding_matrix_numpy,\n",
    "                                                    link_prediction_from_embedding_one_to_other=link_prediction_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "id_to_node = {value:key for key,value in node_to_id.items()}\n",
    "node_embeddings = {}\n",
    "for node in node_to_id:\n",
    "    _id = node_to_id[node]\n",
    "    node_embeddings[node] = embedding_matrix_numpy[_id]\n",
    "pickle.dump(node_embeddings,open(\"models/gf_msg/embeddings.pkl\",\"wb\"))\n",
    "len(node_to_id),embedding_matrix_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_embedding=utils.compute_graph_statistics(predict_adj)\n",
    "metric_origin=utils.compute_graph_statistics(adj_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in metric_origin:\n",
    "    print('%-25s origin:%17.8f, link_pred:%17.8f'%(x,metric_origin[x],metric_embedding[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_different():\n",
    "    different_idx=[]\n",
    "    visited={}\n",
    "    for i in range(len(embedding_matrix_numpy)):\n",
    "        if i not in visited:\n",
    "            different_idx.append(i)\n",
    "            visited[i]=True\n",
    "            for j in range(i+1,len(embedding_matrix_numpy)):\n",
    "                if np.linalg.norm(embedding_matrix_numpy[i]-embedding_matrix_numpy[j])<1e-5:\n",
    "                    if j not in visited:\n",
    "                        visited[j]=True\n",
    "        if i%100==0:\n",
    "            print('\\r%d/%d'%(i,_N),end=\"\")\n",
    "    return different_idx\n",
    "different_idx=compute_different()\n",
    "embeddings_training=embedding_matrix_numpy[different_idx,:]\n",
    "print(embeddings_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(2, n_iter=15000,verbose=1,perplexity = 30) #perplexity=40,\n",
    "projected = tsne.fit_transform(embeddings_training)\n",
    "x = []\n",
    "y = []\n",
    "for value in projected:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "FS = (10, 8)\n",
    "fig, ax = plt.subplots(figsize=FS)\n",
    "# Make points translucent so we can visually identify regions with a high density of overlapping points\n",
    "ax.scatter(x, y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.GAN generate new embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "noise_dim=16\n",
    "g_hidden_dim=[32,64,100]\n",
    "d_hidden_dim=[100,64,32]\n",
    "lendataloader=20\n",
    "Diter=4\n",
    "Giter=1\n",
    "epoch_numbers=30000\n",
    "eval_epoch=400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_training = embeddings_training / np.linalg.norm(embeddings_training, axis=1)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.1 GAN training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "save_idx=0\n",
    "global_best_mmd=10000\n",
    "while(1):\n",
    "    start_time=time.time()\n",
    "    print(save_idx)\n",
    "    flag,best_mmd=utils.gan_train(embeddings_training,batch_size=batch_size,noise_dim=noise_dim,\n",
    "                                   g_hidden_dim=g_hidden_dim,d_hidden_dim=d_hidden_dim,\n",
    "                                   lendataloader=lendataloader,Diter=Diter,Giter=Giter,epoch_numbers=epoch_numbers,eval_epoch=eval_epoch,\n",
    "                                   save_idx=save_idx,learning_rate=1e-4,\n",
    "                                   mmd_beta=0.1,mmd_criterion=0.003,mmd_best_criterion=0.001,dirs='models/gf_msg/')\n",
    "    global_best_mmd=min(global_best_mmd,best_mmd)\n",
    "    if flag==True:\n",
    "        break\n",
    "    save_idx=save_idx+1\n",
    "    print('Using time:%.2f'%(time.time()-start_time))\n",
    "    print(best_mmd)\n",
    "    print(global_best_mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_training[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.2 Load pretrained/trained gan model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *2.2.1 Load provided model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = utils.Generator(noise_dim=noise_dim,embedding_dim=embedding_dim, g_hidden_dim=g_hidden_dim,batch_size=batch_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.load_state_dict(torch.load('models/gf_msg/bestG.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *2.2.2compute ECDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.eval_plot(netG,embedding_matrix=embedding_matrix_numpy,noise_dim=16,mmd_beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'j'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.Sample**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *3.1Generate embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise= torch.randn(_N, noise_dim).cuda()\n",
    "generate_data=netG(noise)\n",
    "generate_data=generate_data.detach().to('cpu').numpy()\n",
    "print(generate_data.shape)\n",
    "np.save('models/gf_msg/gan_embeddings_N.npy', generate_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(2, n_iter=15000,verbose=1,perplexity = 30) #perplexity=40,\n",
    "projected = tsne.fit_transform(generate_data)\n",
    "x = []\n",
    "y = []\n",
    "for value in projected:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "#     for i in range(len(x)):\n",
    "#         plt.scatter(x[i],y[i])\n",
    "#         plt.annotate(labels[i],\n",
    "#                      xy=(x[i], y[i]),\n",
    "#                      xytext=(5, 2),\n",
    "#                      textcoords='offset points',\n",
    "#                      ha='right',\n",
    "#                      va='bottom')\n",
    "FS = (10, 8)\n",
    "fig, ax = plt.subplots(figsize=FS)\n",
    "# Make points translucent so we can visually identify regions with a high density of overlapping points\n",
    "ax.scatter(x, y, alpha=.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_matrix_generate=utils.generate_probability_matrix(_N,generate_data,\n",
    "                                                                        link_prediction_model)\n",
    "_,graphic_seq_generate=utils.evaluate_overlap_torch_generate(_N,_num_of_edges,\n",
    "                                                                                  probability_matrix_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph=utils.revised_Havel_Hakimmi_Algorithm(_N,_num_of_edges,dic,probability_matrix_generate,graphic_seq_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=0\n",
    "tn=0\n",
    "fp=0\n",
    "fn=0\n",
    "for i in range(_N):\n",
    "    for j in range(_N):\n",
    "        if generate_graph[i,j]==1 and adj_origin[i,j]==1:\n",
    "            tp=tp+1\n",
    "        if generate_graph[i,j]==0 and adj_origin[i,j]==1:\n",
    "            fp=fp+1\n",
    "        if generate_graph[i,j]==1 and adj_origin[i,j]==0:\n",
    "            fn=fn+1\n",
    "        if generate_graph[i,j]==0 and adj_origin[i,j]==0:\n",
    "            tn=tn+1\n",
    "    print('\\r%d/%d'%(i,_N),end=\"\")\n",
    "print('\\n')\n",
    "print('Edge overlap between generate graph and original graph')\n",
    "print(generate_graph.shape)\n",
    "total_num=_N*_N\n",
    "print('True Positve:%d, %.2f'%(tp,tp/(tp+fp)))\n",
    "print('False Positve:%d, %.2f'%(fp,fp/(tp+fp)))\n",
    "print('True Negative:%d, %.2f'%(tn,tn/(tn+fn)))\n",
    "print('False Negative:%d, %.2f'%(fn,fn/(tn+fn)))\n",
    "print('Positive:%.2f'%((tp+fp)/total_num))\n",
    "print('Negative:%.2f'%((tn+fn)/total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_graphic_sq_generate=utils.compute_graph_statistics(generate_graph)\n",
    "metric_graphic_sq_generate['edge_overlap']=tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in metric_origin:\n",
    "    print('%-22s origin:%17.8f, link_pred:%17.8f, generate:%17.8f'%(x,metric_origin[x],\n",
    "                                                                    metric_embedding[x],metric_graphic_sq_generate[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
